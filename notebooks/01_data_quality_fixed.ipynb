{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06530560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01. Data Quality Analysis and Cleaning (Fixed)\n",
    "\"\"\"\n",
    "This script is a fixed version of the data quality notebook, with robust handling for missing values visualization.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ffb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ac74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "df = pd.read_csv('../Synthetic_ESG_Greenwashing_Dataset_200_v2.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Schema Validation\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b4a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_columns = [\n",
    "    'project_id', 'organization_name', 'report_year', 'esg_claim_text',\n",
    "    'claim_category', 'claimed_metric_type', 'claimed_value', 'measurement_unit',\n",
    "    'project_location', 'actual_measured_value', 'value_deviation',\n",
    "    'external_validation_score', 'greenwashing_flag', 'controversy_flag',\n",
    "    'source_doc_link', 'report_sentiment_score', 'llm_claim_consistency_score', 'timestamp'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae274429",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_columns = set(expected_columns) - set(df.columns)\n",
    "extra_columns = set(df.columns) - set(expected_columns)\n",
    "print(f\"\\nMissing columns: {missing_columns}\")\n",
    "print(f\"Extra columns: {extra_columns}\")\n",
    "print(f\"All expected columns present: {len(missing_columns) == 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Missing Values Analysis\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percent': missing_percent\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae869d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing Values Analysis:\")\n",
    "missing_columns = missing_df[missing_df['Missing Count'] > 0]\n",
    "print(missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebacdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values only if there are any\n",
    "if len(missing_columns) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_columns['Missing Percent'].plot(kind='bar')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Missing Percentage')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/figures/missing_values.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n✅ No missing values found in the dataset!\")\n",
    "    print(\"This is excellent data quality - no missing value visualization needed.\")\n",
    "    # Optionally, show completeness\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    completeness = (1 - missing_percent/100) * 100\n",
    "    completeness.plot(kind='bar', color='green', alpha=0.7)\n",
    "    plt.title('Data Completeness by Column')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Completeness (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/figures/data_completeness.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38baa19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Duplicate Detection\n",
    "duplicates = df.duplicated().sum()\n",
    "key_columns = ['project_id', 'esg_claim_text']\n",
    "duplicates_key = df.duplicated(subset=key_columns).sum()\n",
    "print(f\"Total duplicate rows: {duplicates}\")\n",
    "print(f\"Duplicate rows based on {key_columns}: {duplicates_key}\")\n",
    "if duplicates > 0:\n",
    "    print(\"\\nDuplicate rows:\")\n",
    "    print(df[df.duplicated()])\n",
    "else:\n",
    "    print(\"\\n✅ No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb02e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Text Quality Analysis\n",
    "df['text_length'] = df['esg_claim_text'].str.len()\n",
    "df['word_count'] = df['esg_claim_text'].str.split().str.len()\n",
    "print(\"Text Length Statistics:\")\n",
    "print(df[['text_length', 'word_count']].describe())\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axes[0].hist(df['text_length'], bins=30, alpha=0.7)\n",
    "axes[0].set_title('Distribution of Text Length (Characters)')\n",
    "axes[0].set_xlabel('Character Count')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[1].hist(df['word_count'], bins=20, alpha=0.7, color='orange')\n",
    "axes[1].set_title('Distribution of Word Count')\n",
    "axes[1].set_xlabel('Word Count')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/text_length_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "short_texts = df[df['text_length'] < 50]\n",
    "long_texts = df[df['text_length'] > 500]\n",
    "print(f\"\\nTexts with < 50 characters: {len(short_texts)}\")\n",
    "print(f\"Texts with > 500 characters: {len(long_texts)}\")\n",
    "if len(short_texts) > 0:\n",
    "    print(\"\\nSample short texts:\")\n",
    "    print(short_texts['esg_claim_text'].head())\n",
    "else:\n",
    "    print(\"\\n✅ No very short texts found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42823c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Data Cleaning\n",
    "df_clean = df.copy()\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "print(f\"Removed {len(df) - len(df_clean)} duplicate rows\")\n",
    "df_clean['esg_claim_text'] = df_clean['esg_claim_text'].str.strip()\n",
    "df_clean['esg_claim_text'] = df_clean['esg_claim_text'].fillna('No claim text provided')\n",
    "df_clean = df_clean[df_clean['esg_claim_text'].str.len() >= 10]\n",
    "print(f\"Removed {len(df) - len(df_clean)} rows with very short texts\")\n",
    "remaining_missing = df_clean.isnull().sum().sum()\n",
    "print(f\"\\nRemaining missing values: {remaining_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Feature Engineering\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data_prep import engineer_features\n",
    "df_features = engineer_features(df_clean)\n",
    "print(f\"Original features: {len(df_clean.columns)}\")\n",
    "print(f\"Engineered features: {len(df_features.columns)}\")\n",
    "print(f\"Feature engineering added: {len(df_features.columns) - len(df_clean.columns)} new features\")\n",
    "original_cols = set(df_clean.columns)\n",
    "new_cols = set(df_features.columns) - original_cols\n",
    "print(f\"\\nNew engineered features: {list(new_cols)}\")\n",
    "missing_in_features = df_features.isnull().sum()\n",
    "if missing_in_features.sum() > 0:\n",
    "    print(\"\\nMissing values in engineered features:\")\n",
    "    print(missing_in_features[missing_in_features > 0])\n",
    "else:\n",
    "    print(\"\\n✅ No missing values in engineered features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f73881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Data Quality Metrics\n",
    "quality_metrics = {\n",
    "    'original_rows': int(len(df)),\n",
    "    'cleaned_rows': int(len(df_clean)),\n",
    "    'rows_removed': int(len(df) - len(df_clean)),\n",
    "    'duplicates_removed': int(len(df) - len(df.drop_duplicates())),\n",
    "    'missing_values_original': int(df.isnull().sum().sum()),\n",
    "    'missing_values_cleaned': int(df_clean.isnull().sum().sum()),\n",
    "    'text_length_min': int(df_clean['esg_claim_text'].str.len().min()),\n",
    "    'text_length_max': int(df_clean['esg_claim_text'].str.len().max()),\n",
    "    'text_length_mean': float(df_clean['esg_claim_text'].str.len().mean()),\n",
    "    'unique_organizations': int(df_clean['organization_name'].nunique()),\n",
    "    'unique_locations': int(df_clean['project_location'].nunique()),\n",
    "    'category_distribution': df_clean['claim_category'].value_counts().to_dict(),\n",
    "    'greenwashing_rate': float(df_clean['greenwashing_flag'].mean())\n",
    "}\n",
    "import json\n",
    "with open('../reports/data_quality_metrics.json', 'w') as f:\n",
    "    json.dump(quality_metrics, f, indent=2)\n",
    "print(\"\\nQuality metrics saved to ../reports/data_quality_metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1099084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Save Cleaned Data\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "df_clean.to_parquet('../data/clean_claims.parquet', index=False)\n",
    "df_features.attrs = {}  # Remove non-serializable attrs\n",
    "df_features.to_parquet('../data/clean_claims_features.parquet', index=False)\n",
    "print(\"Cleaned data saved:\")\n",
    "print(\"- ../data/clean_claims.parquet (cleaned original data)\")\n",
    "print(\"- ../data/clean_claims_features.parquet (with engineered features)\")\n",
    "print(f\"\\nFinal cleaned dataset shape: {df_clean.shape}\")\n",
    "print(f\"Final features dataset shape: {df_features.shape}\")\n",
    "print(\"\\nSample of cleaned data:\")\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e95155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Summary\n",
    "print(\"=== DATA QUALITY ANALYSIS SUMMARY ===\\n\")\n",
    "print(\"1. DATA CLEANING RESULTS:\")\n",
    "print(f\"   - Original rows: {quality_metrics['original_rows']}\")\n",
    "print(f\"   - Cleaned rows: {quality_metrics['cleaned_rows']}\")\n",
    "print(f\"   - Rows removed: {quality_metrics['rows_removed']}\")\n",
    "print(f\"   - Duplicates removed: {quality_metrics['duplicates_removed']}\")\n",
    "print(\"\\n2. MISSING VALUES:\")\n",
    "print(f\"   - Original missing values: {quality_metrics['missing_values_original']}\")\n",
    "print(f\"   - Remaining missing values: {quality_metrics['missing_values_cleaned']}\")\n",
    "print(\"\\n3. TEXT QUALITY:\")\n",
    "print(f\"   - Text length range: {quality_metrics['text_length_min']} - {quality_metrics['text_length_max']} characters\")\n",
    "print(f\"   - Average text length: {quality_metrics['text_length_mean']:.1f} characters\")\n",
    "print(\"\\n4. DATASET CHARACTERISTICS:\")\n",
    "print(f\"   - Unique organizations: {quality_metrics['unique_organizations']}\")\n",
    "print(f\"   - Unique locations: {quality_metrics['unique_locations']}\")\n",
    "print(f\"   - Greenwashing rate: {quality_metrics['greenwashing_rate']:.2%}\")\n",
    "print(\"\\n5. FEATURE ENGINEERING:\")\n",
    "print(f\"   - Original features: {len(df_clean.columns)}\")\n",
    "print(f\"   - Engineered features: {len(df_features.columns)}\")\n",
    "print(f\"   - New features added: {len(df_features.columns) - len(df_clean.columns)}\")\n",
    "print(\"\\n6. NEXT STEPS:\")\n",
    "print(\"   - Data is ready for exploratory analysis\")\n",
    "print(\"   - Features are prepared for model training\")\n",
    "print(\"   - Proceed to notebook 02_eda.ipynb for detailed analysis\") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
