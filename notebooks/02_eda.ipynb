{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on the cleaned ESG greenwashing dataset.\n",
    "\n",
    "## Objectives\n",
    "- Analyze claim categories and distributions\n",
    "- Explore text characteristics and sentiment\n",
    "- Investigate greenwashing patterns\n",
    "- Analyze temporal trends\n",
    "- Examine correlations between features\n",
    "- Generate insights for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "df = pd.read_parquet('../data/clean_claims.parquet')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"=== DATASET OVERVIEW ===\\n\")\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Total features: {len(df.columns)}\")\n",
    "print(f\"Date range: {df['report_year'].min()} - {df['report_year'].max()}\")\n",
    "print(f\"Unique organizations: {df['organization_name'].nunique():,}\")\n",
    "print(f\"Unique locations: {df['project_location'].nunique():,}\")\n",
    "print(f\"Greenwashing rate: {df['greenwashing_flag'].mean():.2%}\")\n",
    "\n",
    "# Display data types\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(\"\\nMissing values:\")\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"\\nNo missing values found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Claim Categories Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze claim categories\n",
    "category_counts = df['claim_category'].value_counts()\n",
    "category_greenwashing = df.groupby('claim_category')['greenwashing_flag'].agg(['mean', 'count'])\n",
    "\n",
    "print(\"=== CLAIM CATEGORIES ANALYSIS ===\\n\")\n",
    "print(\"Category Distribution:\")\n",
    "for cat, count in category_counts.items():\n",
    "    print(f\"{cat}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nGreenwashing Rate by Category:\")\n",
    "for cat in category_counts.index:\n",
    "    rate = category_greenwashing.loc[cat, 'mean']\n",
    "    count = category_greenwashing.loc[cat, 'count']\n",
    "    print(f\"{cat}: {rate:.2%} ({count} claims)\")\n",
    "\n",
    "# Visualize category distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Category counts\n",
    "axes[0].bar(range(len(category_counts)), category_counts.values, color='skyblue')\n",
    "axes[0].set_title('Distribution of Claim Categories')\n",
    "axes[0].set_xlabel('Categories')\n",
    "axes[0].set_ylabel('Number of Claims')\n",
    "axes[0].set_xticks(range(len(category_counts)))\n",
    "axes[0].set_xticklabels(category_counts.index, rotation=45)\n",
    "\n",
    "# Greenwashing rate by category\n",
    "axes[1].bar(range(len(category_greenwashing)), category_greenwashing['mean'], color='lightcoral')\n",
    "axes[1].set_title('Greenwashing Rate by Category')\n",
    "axes[1].set_xlabel('Categories')\n",
    "axes[1].set_ylabel('Greenwashing Rate')\n",
    "axes[1].set_xticks(range(len(category_greenwashing)))\n",
    "axes[1].set_xticklabels(category_greenwashing.index, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/category_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length analysis\n",
    "df['text_length'] = df['esg_claim_text'].str.len()\n",
    "df['word_count'] = df['esg_claim_text'].str.split().str.len()\n",
    "\n",
    "print(\"=== TEXT ANALYSIS ===\\n\")\n",
    "print(\"Text Length Statistics:\")\n",
    "print(df[['text_length', 'word_count']].describe())\n",
    "\n",
    "# Text length by greenwashing status\n",
    "greenwashing_texts = df[df['greenwashing_flag'] == 1]\n",
    "legitimate_texts = df[df['greenwashing_flag'] == 0]\n",
    "\n",
    "print(f\"\\nAverage text length:\")\n",
    "print(f\"Greenwashing claims: {greenwashing_texts['text_length'].mean():.1f} characters\")\n",
    "print(f\"Legitimate claims: {legitimate_texts['text_length'].mean():.1f} characters\")\n",
    "\n",
    "# Visualize text length distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].hist(greenwashing_texts['text_length'], bins=30, alpha=0.7, label='Greenwashing', color='red')\n",
    "axes[0].hist(legitimate_texts['text_length'], bins=30, alpha=0.7, label='Legitimate', color='green')\n",
    "axes[0].set_title('Text Length Distribution by Greenwashing Status')\n",
    "axes[0].set_xlabel('Text Length (characters)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(greenwashing_texts['word_count'], bins=20, alpha=0.7, label='Greenwashing', color='red')\n",
    "axes[1].hist(legitimate_texts['word_count'], bins=20, alpha=0.7, label='Legitimate', color='green')\n",
    "axes[1].set_title('Word Count Distribution by Greenwashing Status')\n",
    "axes[1].set_xlabel('Word Count')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/text_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment scores\n",
    "print(\"=== SENTIMENT ANALYSIS ===\\n\")\n",
    "print(\"Sentiment Score Statistics:\")\n",
    "print(df['report_sentiment_score'].describe())\n",
    "\n",
    "# Sentiment by greenwashing status\n",
    "print(f\"\\nSentiment by Greenwashing Status:\")\n",
    "print(f\"Greenwashing claims: {greenwashing_texts['report_sentiment_score'].mean():.3f}\")\n",
    "print(f\"Legitimate claims: {legitimate_texts['report_sentiment_score'].mean():.3f}\")\n",
    "\n",
    "# Visualize sentiment distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].hist(df['report_sentiment_score'], bins=30, alpha=0.7, color='purple')\n",
    "axes[0].set_title('Distribution of Sentiment Scores')\n",
    "axes[0].set_xlabel('Sentiment Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1].boxplot([legitimate_texts['report_sentiment_score'], \n",
    "                 greenwashing_texts['report_sentiment_score']], \n",
    "                labels=['Legitimate', 'Greenwashing'])\n",
    "axes[1].set_title('Sentiment Scores by Greenwashing Status')\n",
    "axes[1].set_ylabel('Sentiment Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/sentiment_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze trends over time\n",
    "print(\"=== TEMPORAL ANALYSIS ===\\n\")\n",
    "\n",
    "# Claims over time\n",
    "yearly_counts = df['report_year'].value_counts().sort_index()\n",
    "yearly_greenwashing = df.groupby('report_year')['greenwashing_flag'].agg(['mean', 'count'])\n",
    "\n",
    "print(\"Claims by Year:\")\n",
    "for year, count in yearly_counts.items():\n",
    "    print(f\"{year}: {count} claims\")\n",
    "\n",
    "print(\"\\nGreenwashing Rate by Year:\")\n",
    "for year in yearly_counts.index:\n",
    "    rate = yearly_greenwashing.loc[year, 'mean']\n",
    "    count = yearly_greenwashing.loc[year, 'count']\n",
    "    print(f\"{year}: {rate:.2%} ({count} claims)\")\n",
    "\n",
    "# Visualize temporal trends\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].plot(yearly_counts.index, yearly_counts.values, marker='o', linewidth=2, markersize=8)\n",
    "axes[0].set_title('Number of Claims Over Time')\n",
    "axes[0].set_xlabel('Year')\n",
    "axes[0].set_ylabel('Number of Claims')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(yearly_greenwashing.index, yearly_greenwashing['mean'], marker='s', linewidth=2, markersize=8, color='red')\n",
    "axes[1].set_title('Greenwashing Rate Over Time')\n",
    "axes[1].set_xlabel('Year')\n",
    "axes[1].set_ylabel('Greenwashing Rate')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/temporal_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Organization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze organizations\n",
    "print(\"=== ORGANIZATION ANALYSIS ===\\n\")\n",
    "\n",
    "# Top organizations by claim count\n",
    "org_counts = df['organization_name'].value_counts().head(10)\n",
    "org_greenwashing = df.groupby('organization_name')['greenwashing_flag'].agg(['mean', 'count'])\n",
    "org_greenwashing = org_greenwashing[org_greenwashing['count'] >= 3].sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"Top 10 Organizations by Claim Count:\")\n",
    "for org, count in org_counts.items():\n",
    "    print(f\"{org}: {count} claims\")\n",
    "\n",
    "print(\"\\nOrganizations with Highest Greenwashing Rate (â‰¥3 claims):\")\n",
    "for org in org_greenwashing.head(10).index:\n",
    "    rate = org_greenwashing.loc[org, 'mean']\n",
    "    count = org_greenwashing.loc[org, 'count']\n",
    "    print(f\"{org}: {rate:.2%} ({count} claims)\")\n",
    "\n",
    "# Visualize organization analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "axes[0].bar(range(len(org_counts)), org_counts.values, color='lightblue')\n",
    "axes[0].set_title('Top Organizations by Claim Count')\n",
    "axes[0].set_xlabel('Organizations')\n",
    "axes[0].set_ylabel('Number of Claims')\n",
    "axes[0].set_xticks(range(len(org_counts)))\n",
    "axes[0].set_xticklabels(org_counts.index, rotation=45, ha='right')\n",
    "\n",
    "top_orgs_greenwashing = org_greenwashing.head(10)\n",
    "axes[1].bar(range(len(top_orgs_greenwashing)), top_orgs_greenwashing['mean'], color='lightcoral')\n",
    "axes[1].set_title('Top Organizations by Greenwashing Rate')\n",
    "axes[1].set_xlabel('Organizations')\n",
    "axes[1].set_ylabel('Greenwashing Rate')\n",
    "axes[1].set_xticks(range(len(top_orgs_greenwashing)))\n",
    "axes[1].set_xticklabels(top_orgs_greenwashing.index, rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/organization_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlations between numeric features\n",
    "numeric_cols = ['claimed_value', 'actual_measured_value', 'value_deviation', \n",
    "                'external_validation_score', 'report_sentiment_score', \n",
    "                'llm_claim_consistency_score', 'text_length', 'word_count']\n",
    "\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "print(\"=== CORRELATION ANALYSIS ===\\n\")\n",
    "print(\"Correlation with Greenwashing Flag:\")\n",
    "greenwashing_corr = df[numeric_cols + ['greenwashing_flag']].corr()['greenwashing_flag'].sort_values(ascending=False)\n",
    "for feature, corr in greenwashing_corr.items():\n",
    "    if feature != 'greenwashing_flag':\n",
    "        print(f\"{feature}: {corr:.3f}\")\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate insights summary\n",
    "print(\"=== KEY INSIGHTS SUMMARY ===\\n\")\n",
    "\n",
    "print(\"1. DATASET CHARACTERISTICS:\")\n",
    "print(f\"   - Total claims: {len(df):,}\")\n",
    "print(f\"   - Greenwashing rate: {df['greenwashing_flag'].mean():.2%}\")\n",
    "print(f\"   - Date range: {df['report_year'].min()} - {df['report_year'].max()}\")\n",
    "print(f\"   - Organizations: {df['organization_name'].nunique():,}\")\n",
    "\n",
    "print(\"\\n2. CATEGORY INSIGHTS:\")\n",
    "most_common_cat = category_counts.index[0]\n",
    "highest_greenwashing_cat = category_greenwashing['mean'].idxmax()\n",
    "print(f\"   - Most common category: {most_common_cat} ({category_counts.iloc[0]} claims)\")\n",
    "print(f\"   - Highest greenwashing rate: {highest_greenwashing_cat} ({category_greenwashing.loc[highest_greenwashing_cat, 'mean']:.2%})\")\n",
    "\n",
    "print(\"\\n3. TEXT INSIGHTS:\")\n",
    "print(f\"   - Average text length: {df['text_length'].mean():.1f} characters\")\n",
    "print(f\"   - Greenwashing texts are {'longer' if greenwashing_texts['text_length'].mean() > legitimate_texts['text_length'].mean() else 'shorter'} than legitimate texts\")\n",
    "\n",
    "print(\"\\n4. TEMPORAL INSIGHTS:\")\n",
    "if len(yearly_counts) > 1:\n",
    "    trend = \"increasing\" if yearly_greenwashing['mean'].iloc[-1] > yearly_greenwashing['mean'].iloc[0] else \"decreasing\"\n",
    "    print(f\"   - Greenwashing rate trend: {trend}\")\n",
    "    print(f\"   - Peak year: {yearly_greenwashing['mean'].idxmax()} ({yearly_greenwashing['mean'].max():.2%})\")\n",
    "\n",
    "print(\"\\n5. CORRELATION INSIGHTS:\")\n",
    "strongest_corr_feature = greenwashing_corr.index[1]  # Skip greenwashing_flag itself\n",
    "strongest_corr_value = greenwashing_corr.iloc[1]\n",
    "print(f\"   - Strongest correlation with greenwashing: {strongest_corr_feature} ({strongest_corr_value:.3f})\")\n",
    "\n",
    "print(\"\\n6. MODELING RECOMMENDATIONS:\")\n",
    "print(\"   - Use text length and sentiment as important features\")\n",
    "print(\"   - Consider temporal patterns in model training\")\n",
    "print(\"   - Include organization-level features\")\n",
    "print(\"   - Focus on categories with high greenwashing rates\")\n",
    "\n",
    "# Save insights\n",
    "insights = {\n",
    "    'total_claims': len(df),\n",
    "    'greenwashing_rate': df['greenwashing_flag'].mean(),\n",
    "    'date_range': [df['report_year'].min(), df['report_year'].max()],\n",
    "    'organizations': df['organization_name'].nunique(),\n",
    "    'most_common_category': most_common_cat,\n",
    "    'highest_greenwashing_category': highest_greenwashing_cat,\n",
    "    'avg_text_length': df['text_length'].mean(),\n",
    "    'strongest_correlation': {\n",
    "        'feature': strongest_corr_feature,\n",
    "        'correlation': strongest_corr_value\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../reports/eda_insights.json', 'w') as f:\n",
    "    json.dump(insights, f, indent=2)\n",
    "print(\"\\nInsights saved to ../reports/eda_insights.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
} 